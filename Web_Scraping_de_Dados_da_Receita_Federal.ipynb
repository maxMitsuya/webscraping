{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIgsHtU1OizacoWPopqX5x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxMitsuya/webscraping/blob/main/Web_Scraping_de_Dados_da_Receita_Federal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Web Scraping de Dados da Receita Federal"
      ],
      "metadata": {
        "id": "qouSfpndLXcQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este projeto consiste em uma aplicação de web scraping desenvolvida utilizando a biblioteca Beautiful Soup 4. Foi criado como parte de um projeto prático realizado durante o curso na DNC. O código foi desenvolvido para ser executado diretamente no Google Colab, facilitando o acesso e a reprodução."
      ],
      "metadata": {
        "id": "WyYzG-1_Lgni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Objetivo"
      ],
      "metadata": {
        "id": "ebThG-d0N9O5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo principal deste projeto é automatizar o processo de coleta de dados sobre empresas disponibilizados pela Receita Federal. A aplicação realiza o download dos dados diretamente do Banco de Dados da Receita Federal, organizados por data no formato \"ano-mês\" (onde o ano é representado por quatro dígitos e o mês por dois dígitos)."
      ],
      "metadata": {
        "id": "VQGH87iBN_aN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fonte dos dados"
      ],
      "metadata": {
        "id": "yKpD5pr4MU1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os dados utilizados neste projeto são disponibilizados publicamente pela Receita Federal e podem ser acessados através do seguinte link:\n",
        "[Banco de Dados da Receita Federal](https://arquivos.receitafederal.gov.br/cnpj\n",
        ")\n",
        "\n",
        "Os arquivos estão organizados por data, seguindo o padrão \"ano-mês\" (exemplo: 2023-10 para outubro de 2023)."
      ],
      "metadata": {
        "id": "VAUj2JTgMXba"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Funcionalidades"
      ],
      "metadata": {
        "id": "tw0AWn64OWSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Automatização do Download: O script realiza o\n",
        "download automático dos arquivos de dados diretamente do site da Receita Federal.\n",
        "\n",
        "- Organização por Data: Os dados são baixados e organizados de acordo com a data de publicação, facilitando a análise e o processamento posterior.\n",
        "\n",
        "- Execução no Google Colab: O código foi desenvolvido para ser executado diretamente no Google Colab, permitindo que qualquer pessoa possa rodá-lo sem a necessidade de configurar um ambiente local."
      ],
      "metadata": {
        "id": "r5yDFv10OYRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Carregando bibliotecas"
      ],
      "metadata": {
        "id": "LNA0XQejOgf9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYsFI-KILWoF"
      },
      "outputs": [],
      "source": [
        "import os #Manipulação dos arquivos\n",
        "import requests #Requisição de páginas web\n",
        "from bs4 import BeautifulSoup #WebScraping\n",
        "from urllib.parse import urljoin #Join de urls\n",
        "from google.colab import drive #Montar o drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Montando o drive"
      ],
      "metadata": {
        "id": "nDB1MYrNOnt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JXEn5blwOpk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manter a conexão do google drive ativa\n",
        "from google.colab import output\n",
        "output.eval_js('google.colab.kernel.proxyPort(5000)')"
      ],
      "metadata": {
        "id": "wTncidd-Pd2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obs. Devido o volume de dados para realizar o download é interessante manter a conexão do drive para que não haja falhas."
      ],
      "metadata": {
        "id": "ym2onaEbOwV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função para baixar os dados"
      ],
      "metadata": {
        "id": "gXSrVOzQPpFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dados(url_base, data_coleta):\n",
        "\n",
        "  # URL da página que contém os arquivos\n",
        "  url = urljoin(url_base, data_coleta)\n",
        "\n",
        "  # Diretório no Google Drive onde os arquivos serão salvos\n",
        "  save_directory = \"/content/drive/My Drive/\" + data_coleta\n",
        "\n",
        "  # Cria o diretório se ele não existir\n",
        "  if not os.path.exists(save_directory):\n",
        "      os.makedirs(save_directory)\n",
        "\n",
        "  # Função para baixar um arquivo\n",
        "  def download_file(file_url, file_name):\n",
        "      print(f\"Baixando {file_name}...\")\n",
        "      try:\n",
        "          with requests.get(file_url, stream=True) as r:\n",
        "              r.raise_for_status()\n",
        "              with open(file_name, 'wb') as f:\n",
        "                  for chunk in r.iter_content(chunk_size=8192):\n",
        "                      f.write(chunk)\n",
        "          print(f\"{file_name} baixado com sucesso!\")\n",
        "      except Exception as e:\n",
        "          print(f\"Erro ao baixar {file_name}: {e}\")\n",
        "\n",
        "  # Faz a requisição para a página\n",
        "  response = requests.get(url)\n",
        "  response.raise_for_status()  # Verifica se a requisição foi bem-sucedida\n",
        "\n",
        "  # Parseia o conteúdo HTML da página\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  # Lista para armazenar as URLs dos arquivos\n",
        "  file_urls = []\n",
        "\n",
        "  # Encontra todos os links na página\n",
        "  for link in soup.find_all('a'):\n",
        "      href = link.get('href')\n",
        "      if href and href.endswith('.zip'):\n",
        "          file_url = urljoin(url, href)\n",
        "          file_name = os.path.join(save_directory, href.split('/')[-1])\n",
        "          file_urls.append((file_url, file_name))\n",
        "\n",
        "  # Baixa os arquivos em paralelo usando ThreadPoolExecutor\n",
        "  with ThreadPoolExecutor(max_workers=5) as executor:  # Ajuste o número de workers conforme necessário\n",
        "      executor.map(lambda args: download_file(*args), file_urls)\n",
        "\n",
        "  print(\"Todos os arquivos foram baixados.\")"
      ],
      "metadata": {
        "id": "8D3PdUybPi0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função para definir a data de coleta"
      ],
      "metadata": {
        "id": "KI-b8OYfPzIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime, timedelta\n",
        "def data(hoje):\n",
        "  hoje = hoje\n",
        "  mes_passado = hoje.replace(day=1) - timedelta(days=1)\n",
        "  mes = mes_passado.month\n",
        "  ano = mes_passado.year\n",
        "  mes_str = '0' + str(mes) if mes < 10 else str(mes)\n",
        "  data_coleta = f'{ano}' + '-' +mes_str + '/'\n",
        "  return data_coleta\n",
        "\n",
        "hoje = datetime.now()\n",
        "data_coleta = data(hoje)"
      ],
      "metadata": {
        "id": "OC86CgeNP2RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fazendo o download dos dados"
      ],
      "metadata": {
        "id": "A1AnD50IPtlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Primeiro definir a url de coleta\n",
        "url_base = \"https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj/\""
      ],
      "metadata": {
        "id": "wpWDijkWQCZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Baixa os dados usando a função download_dados()\n",
        "download_dados(url_base, data_coleta)"
      ],
      "metadata": {
        "id": "wcPA777KQPCi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}