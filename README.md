# Web Scraping de Dados da Receita Federal

![GitHub](https://img.shields.io/badge/-GitHub-181717?style=flat-square&logo=github)
![Python](https://img.shields.io/badge/-Python-3776AB?style=flat-square&logo=python&logoColor=white)
![BeautifulSoup](https://img.shields.io/badge/-BeautifulSoup4-3776AB?style=flat-square&logo=python&logoColor=white)
![Colab](https://img.shields.io/badge/-Google%20Colab-F9AB00?style=flat-square&logo=google-colab&logoColor=white)

Projeto de web scraping para coleta automatizada de dados de empresas disponibilizados pela Receita Federal do Brasil.

## Resultados Obtidos

- ğŸ“Š Dados estruturados de CNPJs atualizados
- ğŸ“‚ Arquivos organizados por perÃ­odo (formato AAAA-MM)
- âš¡ Processo de coleta automatizado e eficiente
- ğŸ•’ ReduÃ§Ã£o de tempo na obtenÃ§Ã£o dos dados em comparaÃ§Ã£o com mÃ©todos manuais

## ğŸ’¼ AplicaÃ§Ãµes PrÃ¡ticas

Os dados coletados podem ser utilizados para:

- ğŸ” AnÃ¡lise de mercado e competidores
- ğŸ“ˆ Business Intelligence
- ğŸ•µï¸â™‚ï¸ VerificaÃ§Ã£o de informaÃ§Ãµes empresariais
- ğŸ“‘ IntegraÃ§Ã£o com sistemas de CRM e ERP
- ğŸ§  Projetos de Machine Learning e Data Science

## ğŸ¯ Objetivo

Automatizar a coleta de dados corporativos do Banco de Dados PÃºblico da Receita Federal, organizados cronologicamente no formato `AAAA-MM` (ano com 4 dÃ­gitos e mÃªs com 2 dÃ­gitos).

## ğŸ”— Fonte de Dados

Os dados sÃ£o obtidos diretamente do portal oficial da Receita Federal:

[Banco de Dados da Receita Federal](https://arquivos.receitafederal.gov.br/cnpj/)

## âš™ï¸ Funcionalidades Principais

- âœ… Download automatizado de arquivos diretamente da fonte oficial
- ğŸ“… OrganizaÃ§Ã£o inteligente dos dados por perÃ­odo (formato AAAA-MM)
- â˜ï¸ ExecuÃ§Ã£o nativa no Google Colab (sem necessidade de ambiente local)
- â³ Sistema de manutenÃ§Ã£o de conexÃ£o ativa para processos longos

## ğŸš€ Como Executar no Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1X_c6IHV9lnXNM81C339Ia1o0onaaBf7s?usp=sharing)

1. Acesse o notebook via link acima
2. Execute as cÃ©lulas sequencialmente:
   - InstalaÃ§Ã£o automÃ¡tica de dependÃªncias
   - ConfiguraÃ§Ã£o do ambiente
   - Processo de scraping e download
3. Os arquivos serÃ£o salvos no ambiente do Colab e podem ser:
   - Exportados para Google Drive
   - Baixados manualmente

## ğŸ“¦ DependÃªncias

| Biblioteca | VersÃ£o | Finalidade |
|------------|--------|------------|
| BeautifulSoup4 | 4.x | Parsing de HTML/XML |
| requests | 2.x | RequisiÃ§Ãµes HTTP |

Todas as dependÃªncias sÃ£o instaladas automaticamente durante a execuÃ§Ã£o inicial.

## âš ï¸ ManutenÃ§Ã£o de ConexÃ£o

Para evitar desconexÃµes em processos longos:

```python
from google.colab import output
output.eval_js('google.colab.kernel.proxyPort(5000)')
